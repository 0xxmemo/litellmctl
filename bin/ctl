#!/usr/bin/env bash
#
# LiteLLM control CLI — unified runner for all bin/ commands.
#
# Usage:
#   ctl <command> [args...]
#   ctl install              Run the installer
#   ctl auth status          Show auth token status
#   ctl auth chatgpt         Login to ChatGPT
#   ctl auth gemini          Login to Gemini CLI
#   ctl proxy                Start the LiteLLM proxy
#   ctl proxy --port 8000    Start proxy on custom port
#   ctl help                 Show this help
#
# Tab completion:
#   eval "$(ctl --completions)"
#

set -euo pipefail

BIN_DIR="$(cd "$(dirname "$0")" && pwd)"
PROJECT_DIR="$(cd "$BIN_DIR/.." && pwd)"
VENV_DIR="$PROJECT_DIR/venv"

# ── Completions ─────────────────────────────────────────────────────────────

generate_completions() {
  cat <<'COMP'
_ctl_completions() {
  local cur prev commands auth_cmds
  COMPREPLY=()
  cur="${COMP_WORDS[COMP_CWORD]}"
  prev="${COMP_WORDS[COMP_CWORD-1]}"

  commands="auth install proxy start stop status toggle-claude help"
  auth_cmds="chatgpt gemini codex status refresh"

  case "$prev" in
    ctl)
      COMPREPLY=( $(compgen -W "$commands" -- "$cur") )
      return ;;
    auth)
      COMPREPLY=( $(compgen -W "$auth_cmds" -- "$cur") )
      return ;;
    refresh)
      COMPREPLY=( $(compgen -W "chatgpt gemini" -- "$cur") )
      return ;;
    proxy|start)
      COMPREPLY=( $(compgen -W "--port --config --debug" -- "$cur") )
      return ;;
  esac
}
complete -F _ctl_completions ctl
COMP
}

# Also support zsh
generate_zsh_completions() {
  cat <<'COMP'
_ctl_completions() {
  local -a commands auth_cmds
  commands=(
    'auth:Manage OAuth tokens'
    'install:Install/reinstall LiteLLM'
    'proxy:Start the LiteLLM proxy'
    'start:Start the LiteLLM proxy'
    'stop:Stop the running proxy'
    'status:Show auth token status'
    'toggle-claude:Toggle Claude Code between direct API and proxy'
    'help:Show help'
  )
  auth_cmds=(
    'chatgpt:Login to ChatGPT/Codex'
    'gemini:Login to Gemini CLI'
    'codex:Login to ChatGPT/Codex'
    'status:Show token status'
    'refresh:Refresh existing token'
  )

  if (( CURRENT == 2 )); then
    _describe 'command' commands
  elif (( CURRENT == 3 )); then
    case "${words[2]}" in
      auth)    _describe 'auth command' auth_cmds ;;
      refresh) compadd chatgpt gemini ;;
      proxy|start) compadd -- --port --config --debug ;;
    esac
  elif (( CURRENT == 4 )); then
    case "${words[3]}" in
      refresh) compadd chatgpt gemini ;;
    esac
  fi
}
compdef _ctl_completions ctl
COMP
}

# ── Helpers ─────────────────────────────────────────────────────────────────

info()  { printf "\033[1;34m==> %s\033[0m\n" "$*"; }
warn()  { printf "\033[1;33m==> %s\033[0m\n" "$*"; }
error() { printf "\033[1;31m==> %s\033[0m\n" "$*" >&2; }

activate_venv() {
  if [ ! -d "$VENV_DIR" ]; then
    error "No virtualenv found. Run 'ctl install' first."
    exit 1
  fi
  # shellcheck disable=SC1091
  source "$VENV_DIR/bin/activate"
}

load_env() {
  if [ -f "$PROJECT_DIR/.env" ]; then
    set -a
    # shellcheck disable=SC1091
    source "$PROJECT_DIR/.env"
    set +a
  fi
}

find_proxy_pid() {
  lsof -i :4000 -t 2>/dev/null | head -1 || true
}

# ── Commands ────────────────────────────────────────────────────────────────

cmd_install() {
  exec "$BIN_DIR/install" "$@"
}

cmd_auth() {
  activate_venv
  load_env
  exec python3 "$BIN_DIR/auth" "$@"
}

cmd_proxy() {
  activate_venv
  load_env
  unset DEBUG 2>/dev/null || true

  local port=4000
  local config="$PROJECT_DIR/config.yaml"
  local extra_args=()

  while [[ $# -gt 0 ]]; do
    case "$1" in
      --port)   port="$2"; shift 2 ;;
      --config) config="$2"; shift 2 ;;
      *)        extra_args+=("$1"); shift ;;
    esac
  done

  info "Starting LiteLLM proxy on port $port ..."
  exec litellm --config "$config" --port "$port" "${extra_args[@]}"
}

cmd_stop() {
  local pid
  pid=$(find_proxy_pid)
  if [ -z "$pid" ]; then
    warn "No proxy process found on port 4000."
  else
    info "Stopping proxy (PID $pid) ..."
    kill "$pid" 2>/dev/null
    info "Stopped."
  fi
}

cmd_status() {
  activate_venv
  load_env
  python3 "$BIN_DIR/auth" status

  local pid
  pid=$(find_proxy_pid)
  if [ -n "$pid" ]; then
    printf "\033[1mProxy\033[0m\n"
    printf "  PID %s running on port 4000\n\n" "$pid"
  else
    printf "\033[1mProxy\033[0m\n"
    printf "  \033[33mNot running\033[0m\n\n"
  fi
}

show_help() {
  cat <<EOF

$(printf "\033[1mLiteLLM Control CLI\033[0m")

$(printf "\033[1mUsage:\033[0m")  ctl <command> [args...]

$(printf "\033[1mCommands:\033[0m")
  install              Install / reinstall LiteLLM fork
  auth chatgpt         Login to ChatGPT / Codex (browser PKCE)
  auth gemini          Login to Gemini CLI (browser PKCE)
  auth refresh <p>     Refresh token for <chatgpt|gemini>
  auth status          Show auth token status
  proxy [--port N]     Start the LiteLLM proxy (default port 4000)
  stop                 Stop the running proxy
  status               Show auth + proxy status
  toggle-claude        Toggle Claude Code between direct API and proxy
  help                 Show this help

$(printf "\033[1mTab completion:\033[0m")
  bash:  eval "\$(ctl --completions)"
  zsh:   eval "\$(ctl --zsh-completions)"

  Or add to your shell rc:
    echo 'eval "\$(~/.litellm/bin/ctl --completions)"' >> ~/.bashrc
    echo 'eval "\$(~/.litellm/bin/ctl --zsh-completions)"' >> ~/.zshrc

EOF
}

# ── Main ────────────────────────────────────────────────────────────────────

if [[ $# -eq 0 ]]; then
  show_help
  exit 0
fi

case "$1" in
  --completions)     generate_completions; exit 0 ;;
  --zsh-completions) generate_zsh_completions; exit 0 ;;
  install)           shift; cmd_install "$@" ;;
  auth)              shift; cmd_auth "$@" ;;
  proxy|start)       shift; cmd_proxy "$@" ;;
  stop)              shift; cmd_stop "$@" ;;
  status)            shift; cmd_status "$@" ;;
  toggle-claude)     exec "$BIN_DIR/toggle-claude" ;;
  help|-h|--help)    show_help ;;
  *)                 error "Unknown command: $1"; show_help; exit 1 ;;
esac
