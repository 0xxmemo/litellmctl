#!/usr/bin/env python3
"""
litellmctl wizard — interactive config generator.

Walks the user through selecting providers, models, and fallback chains,
then writes a complete config.yaml (backing up the existing one).
"""

import os
import shutil
import sys
from collections import OrderedDict
from pathlib import Path

SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_DIR = SCRIPT_DIR.parent
CONFIG_FILE = PROJECT_DIR / "config.yaml"

# ── Terminal helpers ────────────────────────────────────────────────────────

_TTY = sys.stdout.isatty()
def _c(t, c): return f"\033[{c}m{t}\033[0m" if _TTY else t
def _green(t):  return _c(t, "32")
def _yellow(t): return _c(t, "33")
def _red(t):    return _c(t, "31")
def _cyan(t):   return _c(t, "36")
def _bold(t):   return _c(t, "1")
def _dim(t):    return _c(t, "2")


def _ask(prompt, default=""):
    sys.stdout.write(prompt)
    sys.stdout.flush()
    ans = input().strip()
    return ans if ans else default


def _pick_numbers(prompt, count, default="all"):
    ans = _ask(prompt, default)
    if ans.lower() == "all":
        return list(range(count))
    indices = []
    for part in ans.replace(" ", ",").split(","):
        part = part.strip()
        if part.isdigit() and 1 <= int(part) <= count:
            idx = int(part) - 1
            if idx not in indices:
                indices.append(idx)
    return indices


# ── Provider Templates ─────────────────────────────────────────────────────

PROVIDERS = OrderedDict([
    ("anthropic", {
        "name": "Anthropic (Claude)",
        "desc": "API key — pay-per-use",
        "auth": "api_key",
        "env_vars": ["ANTHROPIC_API_KEY"],
        "role": "primary",
        "tiers": {
            "opus": [{
                "model_name": "claude-opus-4-6",
                "model": "anthropic/claude-opus-4-6",
                "api_key": "os.environ/ANTHROPIC_API_KEY",
            }],
            "sonnet": [{
                "model_name": "claude-sonnet-4-5",
                "model": "anthropic/claude-sonnet-4-5-20250929",
                "api_key": "os.environ/ANTHROPIC_API_KEY",
            }],
            "haiku": [{
                "model_name": "claude-haiku-4-5",
                "model": "anthropic/claude-haiku-4-5-20251001",
                "api_key": "os.environ/ANTHROPIC_API_KEY",
            }],
        },
        "extra_models": [],
    }),
    ("kimi_code", {
        "name": "Kimi Code",
        "desc": "OAuth (device-code) — Allegretto $39/mo",
        "auth": "oauth",
        "auth_cmd": "litellmctl auth kimi",
        "env_vars": [],
        "role": "fallback",
        "tiers": {
            "opus": [{
                "model_name": "kimi-code/kimi-for-coding",
                "model": "kimi_code/kimi-for-coding",
            }],
            "sonnet": [{
                "model_name": "kimi-code/kimi-for-coding",
                "model": "kimi_code/kimi-for-coding",
            }],
        },
        "extra_models": [],
    }),
    ("gemini_cli", {
        "name": "Gemini CLI",
        "desc": "OAuth (PKCE) — Free via Code Assist",
        "auth": "oauth",
        "auth_cmd": "litellmctl auth gemini",
        "env_vars": [],
        "role": "fallback",
        "tiers": {
            "opus": [{
                "model_name": "gemini-cli/gemini-2.5-pro",
                "model": "gemini_cli/gemini-2.5-pro",
            }],
            "sonnet": [{
                "model_name": "gemini-cli/gemini-2.5-flash",
                "model": "gemini_cli/gemini-2.5-flash",
            }],
            "haiku": [{
                "model_name": "gemini-cli/gemini-2.5-flash-lite",
                "model": "gemini_cli/gemini-2.5-flash-lite",
            }],
        },
        "extra_models": [],
    }),
    ("qwen_portal", {
        "name": "Qwen Portal",
        "desc": "OAuth (device-code) — Free 1k req/day",
        "auth": "oauth",
        "auth_cmd": "litellmctl auth qwen",
        "env_vars": [],
        "role": "fallback",
        "tiers": {
            "sonnet": [{
                "model_name": "qwen-cli/qwen3-coder-plus",
                "model": "qwen_portal/qwen3-coder-plus",
            }],
            "haiku": [{
                "model_name": "qwen-cli/qwen3-vl-plus",
                "model": "qwen_portal/vision-model",
            }],
        },
        "extra_models": [],
    }),
    ("dashscope", {
        "name": "DashScope (Alibaba Coding Plan)",
        "desc": "API key — Alibaba Cloud subscription",
        "auth": "api_key",
        "env_vars": ["DASHSCOPE_API_KEY"],
        "role": "fallback",
        "tiers": {
            "opus": [{
                "model_name": "dashscope/qwen3.5-plus",
                "model": "anthropic/qwen3.5-plus",
                "api_key": "os.environ/DASHSCOPE_API_KEY",
                "api_base": "https://coding-intl.dashscope.aliyuncs.com/apps/anthropic",
                "thinking": {"type": "enabled", "budget_tokens": 16000},
            }],
            "sonnet": [{
                "model_name": "dashscope/qwen3-coder-plus",
                "model": "anthropic/qwen3-coder-plus",
                "api_key": "os.environ/DASHSCOPE_API_KEY",
                "api_base": "https://coding-intl.dashscope.aliyuncs.com/apps/anthropic",
            }],
            "haiku": [{
                "model_name": "dashscope/qwen3-max",
                "model": "anthropic/qwen3-max-2026-01-23",
                "api_key": "os.environ/DASHSCOPE_API_KEY",
                "api_base": "https://coding-intl.dashscope.aliyuncs.com/apps/anthropic",
                "thinking": {"type": "enabled", "budget_tokens": 16000},
            }],
        },
        "extra_models": [],
    }),
    ("chatgpt", {
        "name": "ChatGPT / Codex",
        "desc": "OAuth (PKCE) — Pro/Max subscription",
        "auth": "oauth",
        "auth_cmd": "litellmctl auth chatgpt",
        "env_vars": [],
        "role": "fallback",
        "tiers": {
            "opus": [{
                "model_name": "codex/gpt-5.3-codex",
                "model": "chatgpt/gpt-5.3-codex",
                "model_info": {"mode": "responses"},
            }],
            "sonnet": [{
                "model_name": "codex/gpt-5.3-codex-spark",
                "model": "chatgpt/gpt-5.3-codex-spark",
                "model_info": {"mode": "responses"},
            }],
            "haiku": [{
                "model_name": "codex/gpt-5.1-codex-mini",
                "model": "chatgpt/gpt-5.1-codex-mini",
                "model_info": {"mode": "responses"},
            }],
        },
        "extra_models": [
            {"model_name": "codex/gpt-5.2-codex", "model": "chatgpt/gpt-5.2-codex",
             "model_info": {"mode": "responses"}},
            {"model_name": "codex/gpt-5.1-codex", "model": "chatgpt/gpt-5.1-codex",
             "model_info": {"mode": "responses"}},
            {"model_name": "codex/gpt-5.2", "model": "chatgpt/gpt-5.2",
             "model_info": {"mode": "responses"}},
            {"model_name": "codex/gpt-5.1", "model": "chatgpt/gpt-5.1",
             "model_info": {"mode": "responses"}},
        ],
    }),
    ("minimax", {
        "name": "MiniMax",
        "desc": "API key — pay-per-use",
        "auth": "api_key",
        "env_vars": ["MINIMAX_API_KEY"],
        "role": "fallback",
        "tiers": {
            "opus": [{
                "model_name": "minimax/MiniMax-M2.5-highspeed",
                "model": "anthropic/MiniMax-M2.5-highspeed",
                "api_key": "os.environ/MINIMAX_API_KEY",
                "api_base": "https://api.minimax.io/anthropic",
            }],
            "sonnet": [{
                "model_name": "minimax/MiniMax-M2.5-highspeed",
                "model": "anthropic/MiniMax-M2.5-highspeed",
                "api_key": "os.environ/MINIMAX_API_KEY",
                "api_base": "https://api.minimax.io/anthropic",
            }],
            "haiku": [{
                "model_name": "minimax/MiniMax-M2.5-highspeed",
                "model": "anthropic/MiniMax-M2.5-highspeed",
                "api_key": "os.environ/MINIMAX_API_KEY",
                "api_base": "https://api.minimax.io/anthropic",
            }],
        },
        "extra_models": [],
    }),
    ("zai", {
        "name": "Z.AI (GLM)",
        "desc": "API key — pay-per-use",
        "auth": "api_key",
        "env_vars": ["ZAI_API_KEY"],
        "role": "fallback",
        "tiers": {
            "opus": [{
                "model_name": "zai/glm-5",
                "model": "anthropic/glm-5",
                "api_key": "os.environ/ZAI_API_KEY",
                "api_base": "https://api.z.ai/api/anthropic",
            }],
            "sonnet": [{
                "model_name": "zai/glm-4.5-air",
                "model": "anthropic/glm-4.5-air",
                "api_key": "os.environ/ZAI_API_KEY",
                "api_base": "https://api.z.ai/api/anthropic",
            }],
            "haiku": [{
                "model_name": "zai/glm-4.5-flash",
                "model": "anthropic/glm-4.5-flash",
                "api_key": "os.environ/ZAI_API_KEY",
                "api_base": "https://api.z.ai/api/anthropic",
            }],
        },
        "extra_models": [
            {"model_name": n, "model": f"anthropic/{n.split('/', 1)[1]}",
             "api_key": "os.environ/ZAI_API_KEY",
             "api_base": "https://api.z.ai/api/anthropic"}
            for n in [
                "zai/glm-4.5", "zai/glm-4.5v", "zai/glm-4.6", "zai/glm-4.6v",
                "zai/glm-4.7", "zai/glm-4.7-flash", "zai/glm-4.7-flashx",
                "zai/glm-5v", "zai/glm-5-flash",
            ]
        ],
    }),
])

TIERS = ["opus", "sonnet", "haiku"]

# Per-tier default fallback order (matches the hand-tuned config)
DEFAULT_TIER_ORDER = {
    "opus":   ["kimi_code", "minimax", "dashscope", "chatgpt", "gemini_cli", "zai"],
    "sonnet": ["kimi_code", "qwen_portal", "dashscope", "chatgpt", "gemini_cli", "minimax", "zai"],
    "haiku":  ["qwen_portal", "dashscope", "chatgpt", "gemini_cli", "minimax", "zai"],
}


# ── Config generation ──────────────────────────────────────────────────────

def _model_entry(m: dict) -> dict:
    """Build a model_list entry from a template model dict."""
    entry = {"model_name": m["model_name"]}
    if m.get("model_info"):
        entry["model_info"] = dict(m["model_info"])
    params = {"model": m["model"], "timeout": m.get("timeout", 600)}
    for key in ("api_key", "api_base"):
        if key in m:
            params[key] = m[key]
    if "thinking" in m:
        params["thinking"] = dict(m["thinking"])
    entry["litellm_params"] = params
    return entry


def _collect_models(selected_providers: list[str]) -> list[dict]:
    """Collect all model_list entries for selected providers, deduped."""
    seen_names: set[str] = set()
    models: list[dict] = []
    for pid in selected_providers:
        prov = PROVIDERS[pid]
        for tier in TIERS:
            for m in prov["tiers"].get(tier, []):
                if m["model_name"] not in seen_names:
                    seen_names.add(m["model_name"])
                    models.append(_model_entry(m))
        for m in prov.get("extra_models", []):
            if m["model_name"] not in seen_names:
                seen_names.add(m["model_name"])
                models.append(_model_entry(m))
    return models


def _build_fallbacks(
    primary_tiers: list[str],
    primary_provider: str,
    fallback_providers: list[str],
    fallback_order: dict[str, list[str]],
) -> list[dict]:
    """Build the fallback chain list for router_settings."""
    fallbacks: list[dict] = []
    prov = PROVIDERS[primary_provider]
    for tier in primary_tiers:
        tier_models = prov["tiers"].get(tier, [])
        if not tier_models:
            continue
        primary_name = tier_models[0]["model_name"]
        chain: list[str] = []
        for fpid in fallback_order.get(tier, []):
            if fpid not in fallback_providers:
                continue
            fp = PROVIDERS[fpid]
            for m in fp["tiers"].get(tier, []):
                if m["model_name"] != primary_name and m["model_name"] not in chain:
                    chain.append(m["model_name"])
        if chain:
            fallbacks.append({primary_name: chain})
    return fallbacks


def _render_yaml_value(v, indent=0):
    """Render a value for YAML output."""
    prefix = "  " * indent
    if isinstance(v, dict):
        lines = []
        for dk, dv in v.items():
            if isinstance(dv, (dict, list)):
                lines.append(f"{prefix}{dk}:")
                lines.append(_render_yaml_value(dv, indent + 1))
            else:
                lines.append(f"{prefix}{dk}: {dv}")
        return "\n".join(lines)
    elif isinstance(v, list):
        lines = []
        for item in v:
            lines.append(f"{prefix}- {item}")
        return "\n".join(lines)
    elif isinstance(v, bool):
        return f"{prefix}{str(v).lower()}"
    else:
        return f"{prefix}{v}"


def _generate_yaml(models: list[dict], fallbacks: list[dict]) -> str:
    """Render config.yaml as a clean YAML string."""
    lines: list[str] = ["model_list:"]

    for entry in models:
        lines.append(f"  - model_name: {entry['model_name']}")
        if "model_info" in entry:
            lines.append("    model_info:")
            for k, v in entry["model_info"].items():
                lines.append(f"      {k}: {v}")
        lines.append("    litellm_params:")
        params = entry["litellm_params"]
        for k, v in params.items():
            if isinstance(v, dict):
                lines.append(f"      {k}:")
                for sk, sv in v.items():
                    lines.append(f"        {sk}: {sv}")
            else:
                lines.append(f"      {k}: {v}")

    lines.append("")
    lines.append("router_settings:")
    lines.append("  num_retries: 2")
    lines.append("  timeout: 600")
    lines.append("  retry_after: 5")
    lines.append("  allowed_fails: 1")

    if fallbacks:
        lines.append("  fallbacks:")
        for fb in fallbacks:
            for primary, chain in fb.items():
                lines.append(f"    - {primary}:")
                lines.append("        [")
                for m in chain:
                    lines.append(f"          {m},")
                lines.append("        ]")

    lines.append("")
    lines.append("litellm_settings:")
    lines.append("  drop_params: true")
    lines.append("  set_verbose: false")
    lines.append("  request_timeout: 600")
    lines.append("")
    lines.append("general_settings:")
    lines.append("  master_key: os.environ/LITELLM_MASTER_KEY")
    lines.append("")
    lines.append("environment_variables:")
    lines.append("  # Token dirs & auth files are set in .env (machine-specific paths)")
    lines.append("")

    return "\n".join(lines)


# ── Interactive wizard ─────────────────────────────────────────────────────

def run_wizard():
    print()
    print(_bold("litellmctl config wizard"))
    print(_dim("=" * 50))

    # ── Step 1: Primary provider & tiers ──
    primaries = [(pid, p) for pid, p in PROVIDERS.items() if p["role"] == "primary"]
    if len(primaries) == 1:
        primary_id, primary = primaries[0]
        print(f"\n  Primary provider: {_bold(primary['name'])}")
    else:
        print(f"\n{_bold('Primary providers:')}")
        for i, (pid, p) in enumerate(primaries, 1):
            print(f"  [{i}] {p['name']:<30} {_dim(p['desc'])}")
        idx = _pick_numbers("\nSelect primary provider [1]: ", len(primaries), "1")
        primary_id, primary = primaries[idx[0] if idx else 0]

    available_tiers = [t for t in TIERS if t in primary["tiers"]]
    print(f"\n{_bold('Which tiers to expose?')}")
    for i, t in enumerate(available_tiers, 1):
        model_name = primary["tiers"][t][0]["model_name"]
        print(f"  [{i}] {t:<10} -> {model_name}")
    tier_idx = _pick_numbers(
        f"\nSelect tiers (comma-separated, or 'all') [all]: ",
        len(available_tiers),
    )
    selected_tiers = [available_tiers[i] for i in tier_idx] if tier_idx else available_tiers
    print(f"  -> {_green(', '.join(selected_tiers))}")

    # ── Step 2: Fallback providers ──
    fallbacks_list = [(pid, p) for pid, p in PROVIDERS.items() if p["role"] == "fallback"]
    print(f"\n{_bold('Available fallback providers:')}")
    for i, (pid, p) in enumerate(fallbacks_list, 1):
        auth_label = "OAuth" if p["auth"] == "oauth" else "API key"
        tiers_avail = ", ".join(t for t in TIERS if t in p["tiers"])
        print(f"  [{i}] {p['name']:<28} {auth_label:<10} {_dim(p['desc'])}")
        print(f"      {_dim('Tiers: ' + tiers_avail)}")

    fb_idx = _pick_numbers(
        f"\nSelect fallback providers (comma-separated, or 'all') [all]: ",
        len(fallbacks_list),
    )
    selected_fb_ids = (
        [fallbacks_list[i][0] for i in fb_idx]
        if fb_idx is not None
        else [pid for pid, _ in fallbacks_list]
    )
    selected_fb_names = [PROVIDERS[pid]["name"] for pid in selected_fb_ids]
    print(f"  -> {_green(', '.join(selected_fb_names))}")

    # ── Step 3: Fallback ordering per tier ──
    fallback_order: dict[str, list[str]] = {}
    print(f"\n{_bold('Fallback order per tier')}")
    print(_dim("  (enter reordered numbers, or press Enter to accept default)"))

    for tier in selected_tiers:
        # Build the default order for this tier from the template
        default_for_tier = DEFAULT_TIER_ORDER.get(tier, [])
        available_for_tier = [
            pid for pid in default_for_tier
            if pid in selected_fb_ids and tier in PROVIDERS[pid]["tiers"]
        ]
        # Add any selected providers not in the default order
        for pid in selected_fb_ids:
            if pid not in available_for_tier and tier in PROVIDERS[pid]["tiers"]:
                available_for_tier.append(pid)

        if not available_for_tier:
            fallback_order[tier] = []
            continue

        print(f"\n  {_bold(tier)}:")
        for i, pid in enumerate(available_for_tier, 1):
            m = PROVIDERS[pid]["tiers"][tier][0]
            print(f"    [{i}] {m['model_name']:<40} ({PROVIDERS[pid]['name']})")

        default_nums = ",".join(str(i) for i in range(1, len(available_for_tier) + 1))
        ans = _ask(f"  Order [{default_nums}]: ", default_nums)

        order: list[str] = []
        for part in ans.replace(" ", ",").split(","):
            part = part.strip()
            if part.isdigit() and 1 <= int(part) <= len(available_for_tier):
                pid = available_for_tier[int(part) - 1]
                if pid not in order:
                    order.append(pid)
        fallback_order[tier] = order if order else available_for_tier

    # ── Step 4: Generate ──
    all_selected = [primary_id] + selected_fb_ids
    models = _collect_models(all_selected)
    fallbacks = _build_fallbacks(selected_tiers, primary_id, selected_fb_ids, fallback_order)
    yaml_content = _generate_yaml(models, fallbacks)

    # Summary
    print(f"\n{_bold('Summary')}")
    print(_dim("-" * 50))
    print(f"  Primary:   {primary['name']} ({', '.join(selected_tiers)})")
    print(f"  Fallbacks: {', '.join(selected_fb_names)}")
    print(f"  Models:    {len(models)} total")

    # Show env vars / auth commands needed
    env_vars_needed: list[str] = []
    auth_cmds_needed: list[str] = []
    for pid in all_selected:
        p = PROVIDERS[pid]
        env_vars_needed.extend(p.get("env_vars", []))
        if p.get("auth_cmd"):
            auth_cmds_needed.append(p["auth_cmd"])
    env_vars_needed.append("LITELLM_MASTER_KEY")

    if env_vars_needed:
        print(f"\n  {_bold('Required .env vars:')} {', '.join(sorted(set(env_vars_needed)))}")
    if auth_cmds_needed:
        print(f"  {_bold('Auth commands:')}")
        for cmd in auth_cmds_needed:
            print(f"    {cmd}")
    print()

    # Confirm
    ans = _ask("  Write config.yaml? [Y/n]: ", "y")
    if ans.lower().startswith("n"):
        print(_yellow("  Aborted."))
        return

    # Backup and write
    if CONFIG_FILE.exists():
        backup = CONFIG_FILE.with_suffix(".yaml.bak")
        shutil.copy2(CONFIG_FILE, backup)
        print(_dim(f"  Backed up -> {backup.name}"))

    CONFIG_FILE.write_text(yaml_content)
    print(_green(f"  Written to {CONFIG_FILE}"))
    print()


# ── CLI ────────────────────────────────────────────────────────────────────

if __name__ == "__main__":
    try:
        run_wizard()
    except KeyboardInterrupt:
        print(_yellow("\nAborted."))
        sys.exit(130)
    except Exception as e:
        print(_red(f"\nError: {e}"))
        sys.exit(1)
