tiers:
  - opus
  - sonnet
  - haiku

# Display / load order in the wizard
load_order:
  - chatgpt
  - kimi_code
  - gemini_cli
  - qwen_portal
  - alibaba
  - minimax
  - anthropic
  - zai

# Per-tier primary provider and fallback order (matches the hand-tuned config)
#   primary  = the provider whose model_name the alias points to
#   fallbacks = tried in order when the primary fails
primary:
  opus: chatgpt
  sonnet: anthropic
  haiku: chatgpt

fallback_order:
  opus:
    - alibaba
    - kimi_code
    - anthropic
    - zai
  sonnet:
    - chatgpt
    - qwen_portal
    - alibaba
    - zai
  haiku:
    - qwen_portal
    - alibaba
    - anthropic
    - zai

# OAuth auth-file â†’ .env variable mapping (used by wizard to check readiness)
auth_files:
  chatgpt:
    file: auth.chatgpt.json
    dir_var: CHATGPT_TOKEN_DIR
    file_var: CHATGPT_AUTH_FILE
  gemini_cli:
    file: auth.gemini_cli.json
    dir_var: GEMINI_CLI_TOKEN_DIR
    file_var: GEMINI_CLI_AUTH_FILE
  qwen_portal:
    file: auth.qwen_portal.json
    dir_var: QWEN_PORTAL_TOKEN_DIR
    file_var: QWEN_PORTAL_AUTH_FILE
  kimi_code:
    file: auth.kimi_code.json
    dir_var: KIMI_CODE_TOKEN_DIR
    file_var: KIMI_CODE_AUTH_FILE

router_settings:
  num_retries: 2
  timeout: 120
  retry_after: 1
  allowed_fails: 3
  cooldown_time: 15
  routing_strategy: simple-shuffle

litellm_settings:
  drop_params: true
  set_verbose: false
  request_timeout: 120
  cache: true
  cache_params:
    type: local
    ttl: 300
  callbacks:
    - bin.system_prompt_injection.proxy_handler_instance

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
